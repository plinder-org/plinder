{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLINDER MLSB Challenge\n",
    "\n",
    "1. [Background information](#background-information)\n",
    "2. [Accessing and loading data for training](#load-data) \n",
    "\n",
    "The goal of this tutorial is to provide background information for the MLSB/PLINDER challenge, as well as a simple hands-on demo for how participants can access and use the plinder dataset.\n",
    "\n",
    "Specifically, we will cover:\n",
    "\n",
    "- Background information\n",
    "- Accessing and loading data for training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background information <a id=\"background-information\"></a>\n",
    "\n",
    "For background information on the rules of the challenge, see [link]() for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing and loading data for training <a class=\"anchor\" id=\"load-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to demonstrate how to get the key input data:\n",
    "- protein receptor fasta sequence\n",
    "- small molecules ligand SMILES string\n",
    "- access to linked _apo_ and _pred_ structure\n",
    "\n",
    "\n",
    "In the process, we will show:\n",
    "- How to download the _PLINDER_ data\n",
    "- How to query _PLINDER_ index and splits to select relevant data using `plinder.core` API\n",
    "- Extract task-specific data one might want to use for training a task-specific ML model, eg. one protein, one ligand\n",
    "- How to use `plinder.core` API and `PlinderDataset` class to supply dataset inputs for `train` or `val` splits\n",
    "- Load linked `apo` and `pred` structures\n",
    "- Example how to create a simple diversity sampler based on cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download _PLINDER_ <a class=\"anchor\" id=\"download-plinder\"></a>\n",
    "\n",
    "To download, run: `plinder_download --release 2024-06 --iteration v2 --yes` <br>\n",
    "This will download and unpack all neccesary files. For more information on download check out [Dataset Tutorial](https://plinder-org.github.io/plinder/tutorial/dataset.html#getting-the-data)\n",
    "\n",
    ":::{note} The dataset is hundreds of gigabytes in size; downloading and extracting should take about 40 minutes. If you want to play around with a toy example dataset, please use `--iteration tutorial`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading _PLINDER_  <a class=\"anchor\" id=\"loading-plinder\"></a>\n",
    "\n",
    "We recommend users interact with the dataset using _PLINDER_ Python API.\n",
    "\n",
    "To install the API run: ``pip install plinder[loader]``. If you are using `zsh` terminal, you will have to quote the package like ``\"plinder[loader]\"``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import pandas as pd\n",
    "from plinder.core.scores import query_index\n",
    "\n",
    "os.environ[\"PLINDER_OFFLINE\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load _PLINDER_ index with selected columns from annotations table\n",
    "For a full list with descriptions, please refer to [docs](https://plinder-org.github.io/plinder/dataset.html#annotation-tables-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Project was not passed and could not be determined from the environment.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get plinder index with selected annotation columns specified\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plindex \u001b[38;5;241m=\u001b[39m \u001b[43mquery_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mligand_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mligand_rdkit_canonical_smiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mligand_is_ion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mligand_is_artifact\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem_num_ligand_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem_num_neighboring_protein_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mholo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem_num_neighboring_protein_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/coding/plinder/src/plinder/core/scores/index.py:37\u001b[0m, in \u001b[0;36mquery_index\u001b[0;34m(columns, filters)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mQuery the index database.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    the index results\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 37\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_plinder_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry_pdb_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/coding/plinder/src/plinder/core/utils/cpl.py:144\u001b[0m, in \u001b[0;36mget_plinder_path\u001b[0;34m(rel, download, force_progress)\u001b[0m\n\u001b[1;32m    142\u001b[0m client \u001b[38;5;241m=\u001b[39m _CLIENTS\u001b[38;5;241m.\u001b[39mget(root)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mGSClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_cache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     _CLIENTS[root] \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m    146\u001b[0m remote \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mplinder_remote\n",
      "File \u001b[0;32m~/conda/envs/plinder/lib/python3.10/site-packages/cloudpathlib/gs/gsclient.py:101\u001b[0m, in \u001b[0;36mGSClient.__init__\u001b[0;34m(self, application_credentials, credentials, project, storage_client, file_cache_mode, local_cache_dir, content_type_method, download_chunks_concurrently_kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mStorageClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DefaultCredentialsError:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m StorageClient\u001b[38;5;241m.\u001b[39mcreate_anonymous_client()\n",
      "File \u001b[0;32m~/conda/envs/plinder/lib/python3.10/site-packages/google/cloud/storage/client.py:227\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, client_info, client_options, use_auth_w_custom_endpoint, extra_headers)\u001b[0m\n\u001b[1;32m    224\u001b[0m             no_project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    225\u001b[0m             project \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<none>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Validate that the universe domain of the credentials matches the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# universe domain of the client.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials\u001b[38;5;241m.\u001b[39muniverse_domain \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muniverse_domain:\n",
      "File \u001b[0;32m~/conda/envs/plinder/lib/python3.10/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _http\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43m_ClientProjectMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     Client\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m, credentials\u001b[38;5;241m=\u001b[39mcredentials, client_options\u001b[38;5;241m=\u001b[39mclient_options, _http\u001b[38;5;241m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/conda/envs/plinder/lib/python3.10/site-packages/google/cloud/client/__init__.py:271\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    268\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_default(project)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject was not passed and could not be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetermined from the environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(project, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    277\u001b[0m     project \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Project was not passed and could not be determined from the environment."
     ]
    }
   ],
   "source": [
    "# get plinder index with selected annotation columns specified\n",
    "plindex = query_index(\n",
    "    columns=[\"system_id\", \"ligand_id\",\n",
    "             \"ligand_rdkit_canonical_smiles\", \"ligand_is_ion\",\n",
    "             \"ligand_is_artifact\", \"system_num_ligand_chains\",\n",
    "             \"system_num_neighboring_protein_chains\"],\n",
    "    filters=[\n",
    "        (\"system_type\", \"==\", \"holo\"),\n",
    "        (\"system_num_neighboring_protein_chains\", \"<=\", 5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of system neighboring protein chains\n",
    "plindex.groupby(\"system_num_neighboring_protein_chains\").system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting specific data using _PLINDER_ annotations  <a class=\"anchor\" id=\"extracting-annotations\"></a>\n",
    "As we can see just from the data tables above - a significant fraction of _PLINDER_ systems contain complex multi protein chain systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task specific selection\n",
    "If we would like to focus on single protein and single ligand systems for training, we can use the annotated columns to filter out systems that:\n",
    "- contain only one protein chain\n",
    "- only one ligand\n",
    "\n",
    "Remember: In _PLINDER_ artifacts and (single atom) ions are also included in the index if they are part of the pocket.\n",
    "- We can use columns `ligand_is_ion` and `ligand_is_artifact` to only select \"proper\" ligands.\n",
    "\n",
    "Let's find out how many annotated ligands are \"proper\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \"proper\" ligands that are not ions or artifacts\n",
    "plindex[\"ligand_is_proper\"] = (\n",
    "    ~plindex[\"ligand_is_ion\"] & ~plindex[\"ligand_is_artifact\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex.groupby(\"ligand_is_proper\").system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User choice\n",
    "\n",
    "The annotations table gives flexibility to choose the systems for training:\n",
    "- One could strictly choose to use only the data that contains single protein single ligand systems\n",
    "- Alternatively one could expand the number of systems to include systems containing single proper ligands, and optionally ignore the artifacts and ions in the pocket\n",
    "\n",
    "Let's compare the numbers of such systems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask for single receptor single ligand systems\n",
    "systems_1p1l = (plindex[\"system_num_neighboring_protein_chains\"] == 1) & (plindex[\"system_num_ligand_chains\"] == 1)\n",
    "\n",
    "# make count of these \"proper\" ligands per system\n",
    "plindex[\"system_proper_num_ligand_chains\"] = plindex.groupby(\"system_id\")[\"ligand_is_proper\"].transform(\"sum\")\n",
    "\n",
    "# create mask only for single receptor single \"proper\" ligand systems\n",
    "systems_proper_1p1l = (plindex[\"system_num_neighboring_protein_chains\"] == 1) & (plindex[\"system_proper_num_ligand_chains\"] == 1) & plindex[\"ligand_is_proper\"]\n",
    "\n",
    "print(f\"Number of single receptor single ligand systems: {sum(systems_1p1l)}\")\n",
    "print(f\"Number of single receptor single \\\"proper\\\" ligand systems: {sum(systems_proper_1p1l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see - the second choice can provide up to 20% more data for training, however, the caveat is that some of the interactions made by artifacts or ions may influence the binding pose of the \"proper\" ligand. The user could come up with further strategies to filtering using annotations table or external tools, but this is beyond the scope of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading splits\n",
    "\n",
    "Now, after curating the systems of interest, let's have a look at the splits using _PLINDER_ API.\n",
    "\n",
    "- How to use {mod}`plinder.core` API and class {class}`PlinderDataset` class to supply dataset inputs for `train` or `val` splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core import get_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the splits\n",
    "\n",
    "The `get_split` function provided the current _PLINDER_ split, the detailed description of this DataFrame is provide in the [dataset documentation](https://plinder-org.github.io/plinder/dataset.html#splits-splits), but for our practical purposes we are mostly interested in `system_id` and `split` that assigns each of our systems to a specific split category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current plinder split\n",
    "split_df = get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some specific method developers working on _flexible_ docking may also find handy the annotation column `system_has_apo_or_pred` indicating if the system has available `apo` or `pred` linked structures (see later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.groupby([\"split\", \"system_has_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity let's merge plindex and split DataFrames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to a single DataFrame\n",
    "plindex_split = plindex.merge(split_df, on=\"system_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting links to `apo` or `pred` structures <a class=\"anchor\" id=\"getting-apo-pred\"></a>\n",
    ":::{currentmodule} plinder.core\n",
    ":::\n",
    "\n",
    "For users interested in including `apo` and `pred` structures in their workflow, all the information needed can be obtained from the function {func}`query_links`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.scores import query_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = query_links(\n",
    "    columns=[\"reference_system_id\", \"id\", \"sort_score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} The table is sorted by `sort_score` that is resolution for `apo`s and `plddt` for `pred`s. The `apo` or `pred` is specified in the additionally added `kind` column.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a user wants to consider only one linked structure per system - we can easily drop duplicates, first sorting by `sort_score`. Using this priority score, `pred` structures will not be used unless there is no `apo` available. Alternative can be achieved by sorting with `ascending=False`, or filtering by `kind==\"pred\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_links_df = links_df.sort_values(\"sort_score\", ascending=True).drop_duplicates(\"reference_system_id\")\n",
    "single_links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have links to `apo` / `pred` structures, we can see how many of those are available for our single protein single ligand systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_split[systems_1p1l].groupby([\"split\", \"system_has_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_split_1p1l_links = plindex_split[systems_1p1l].merge(single_links_df, left_on=\"system_id\", right_on=\"reference_system_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how many systems have linked structures\n",
    "plindex_split_1p1l_links['system_has_linked_apo_or_pred'] = ~plindex_split_1p1l_links.filename.isna()\n",
    "plindex_split_1p1l_links.groupby([\"split\", \"system_has_linked_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting final dataset\n",
    "Let's select only the set that has linked structures for flexible docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_final_df = plindex_split_1p1l_links[\n",
    "    (plindex_split_1p1l_links.system_has_linked_apo_or_pred) & (plindex_split_1p1l_links.split != \"removed\")\n",
    "]\n",
    "plindex_final_df.groupby([\"split\", \"system_has_linked_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_final_df[[\"ligand_rdkit_canonical_smiles\", \"filename\"]].iloc[0].filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using _PLINDER_ API to load dataset by split <a class=\"anchor\" id=\"api-load-split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.loader import get_model_input_files, PlinderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PlinderDataset(\n",
    "    df=plindex_final_df,\n",
    "    split=\"train\",\n",
    "    num_alternative_structures=2,\n",
    "    file_paths_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{currentmodule} plinder.core.loader\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "function {func}`get_model_input_files` accepts `split =` \"train\", \"val\" or \"test\"\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = get_model_input_files(\n",
    "    plindex_final_df,\n",
    "    split = \"val\",\n",
    "    max_num_sample = 10,\n",
    "    num_alternative_structures = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} if files not already available this downloads them to `~/.local/share/plinder/{PLINDER_RELEASE}/{PLINDER_ITERATION}` directory\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "sample_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using _PLINDER_ clusters in sampling <a class=\"anchor\" id=\"cluster-sampling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define diversity sampler function\n",
    ":::{currentmodule} plinder.core\n",
    ":::\n",
    "\n",
    "In general, diversity can be sampled using cluster information described [here](https://plinder-org.github.io/plinder/dataset.html#clusters-clusters). All cluster information can easily be added to `plindex` by calling the following function {func}`get_extended_plindex`. <br>\n",
    "Here, we have provided an example of how one might use the function `get_diversity_samples` which is based on  `torch.utils.data.WeightedRandomSampler`. This example is meant for demonstration purposes and users are encouraged to come up with sampling strategy that suits their need. <br>\n",
    "For this example, we are going to use the sample dversity based on the following parameters:\n",
    "`metric=\"pli_qcov\"`,  `threshold=70` and `cluster=communities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.loader import  get_diversity_samples\n",
    "from plinder.core import get_extended_plindex\n",
    "from typing import Literal\n",
    "\n",
    "# Example sampler function, this is for demonstration purposes,\n",
    "# users are advised to write a sampler that suit their need\n",
    "def get_diversity_samples(\n",
    "    split_df: pd.DataFrame,\n",
    "    split: Literal[\"train\", \"val\", \"test\"] = \"train\",\n",
    "    metric: str = \"pli_qcov\",\n",
    "    threshold: int = 70,\n",
    "    cluster_type: str = \"communities\"):\n",
    "\n",
    "    from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "    split_df = split_df[split_df.split == split]\n",
    "    cluster_counts = (split_df[f\"{metric}__{threshold}__{cluster_type}\"]\\\n",
    "                      .value_counts().rename(\"cluster_count\"))\n",
    "    split_df = split_df.merge(\n",
    "        cluster_counts,\n",
    "        left_on=f\"{metric}__{threshold}__{cluster_type}\",\n",
    "        right_index=True)\n",
    "    split_df.reset_index(inplace=True)\n",
    "    cluster_weights = 1.0 / split_df.cluster_count.values\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=cluster_weights,\n",
    "        num_samples=len(cluster_weights))\n",
    "    sampler_index = [i for i in sampler]\n",
    "    return split_df.loc[\n",
    "        tuple(sampler_index),\n",
    "        (\"system_id\", \"split\")].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this takes a couple of minutes to run\n",
    "plindex_extended = get_extended_plindex()\n",
    "cluster_columns = [\"system_id\"] + [col for col in plindex_extended.columns \\\n",
    "                                   if (\"communities\" in col) or (\"component\" in col)]\n",
    "plindex_with_clusters = plindex_final_df.merge(plindex_extended[cluster_columns], on=\"system_id\", how=\"left\")\n",
    "sampled_df =  get_diversity_samples(split_df=plindex_with_clusters,\n",
    "                                    metric=\"pli_qcov\",\n",
    "                                    threshold=70,\n",
    "                                    cluster_type=\"communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dataframe could then be passed to {func}`get_model_input_files` the same way `plindex_final_df` was used above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
