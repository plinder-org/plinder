{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLSB/PLINDER Data Access\n",
    "(mlsb-notebook-target)=\n",
    "\n",
    "The goal of this tutorial is to provide background information for the MLSB/PLINDER challenge, as well as a simple hands-on demo for how participants can access and use the _PLINDER_ dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background information <a id=\"background-information\"></a>\n",
    "\n",
    "For background information on the rules of the challenge, see [MLSB/P(L)INDER challenge rules](#mlsb-rules-target) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing and loading data for training <a class=\"anchor\" id=\"load-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to demonstrate how to get the key input data:\n",
    "- protein receptor fasta sequence\n",
    "- small molecules ligand SMILES string\n",
    "- access to linked _apo_ and _pred_ structure\n",
    "\n",
    "\n",
    "In the process, we will show:\n",
    "- How to download the _PLINDER_ data\n",
    "- How to query _PLINDER_ index and splits to select relevant data using `plinder.core` API\n",
    "- Extract task-specific data one might want to use for training a task-specific ML model, eg. one protein, one ligand\n",
    "- How to use `plinder.core` API to:\n",
    "    - supply dataset inputs for `train` or `val` splits\n",
    "    - load linked `apo` and `pred` structures\n",
    "    - use diversity subsampling based on cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download _PLINDER_ <a class=\"anchor\" id=\"download-plinder\"></a>\n",
    "\n",
    "To download, run: `plinder_download --release 2024-06 --iteration v2 --yes` <br>\n",
    "This will download and unpack all neccesary files. For more information on download check out [Dataset Tutorial](https://plinder-org.github.io/plinder/tutorial/dataset.html#getting-the-data)\n",
    "\n",
    ":::{note} The dataset is hundreds of gigabytes in size; downloading and extracting should take about 40 minutes. If you want to play around with a toy example dataset, please use `--iteration tutorial`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading _PLINDER_  <a class=\"anchor\" id=\"loading-plinder\"></a>\n",
    "\n",
    "We recommend users interact with the dataset using _PLINDER_ Python API.\n",
    "\n",
    "To install the API run: ``pip install plinder[loader]``. If you are using `zsh` terminal, you will have to quote the package like ``\"plinder[loader]\"``\n",
    "\n",
    "NOTE: once the _PLINDER_ is downloaded locally, you can use it in offline mode to save time for data queries with: `os.environ[\"PLINDER_OFFLINE\"] = \"true\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# once the _PLINDER_ is downloaded you can set this to true\n",
    "os.environ[\"PLINDER_OFFLINE\"] = \"false\"\n",
    "# os.environ[\"PLINDER_OFFLINE\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load _PLINDER_ index with selected columns from annotations table\n",
    "For a full list with descriptions, please refer to [docs](https://plinder-org.github.io/plinder/dataset.html#annotation-tables-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.scores import query_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get plinder index with selected annotation columns specified\n",
    "plindex = query_index(\n",
    "    columns=[\"system_id\", \"ligand_id\",\n",
    "             \"ligand_rdkit_canonical_smiles\", \"ligand_is_ion\",\n",
    "             \"ligand_is_artifact\", \"system_num_ligand_chains\",\n",
    "             \"system_num_protein_chains\",\n",
    "             \"pli_qcov__100__strong__component\",\n",
    "             \"ligand_is_proper\",\n",
    "             \"system_proper_num_ligand_chains\",\n",
    "             ],\n",
    "    filters=[\n",
    "        (\"system_type\", \"==\", \"holo\"),\n",
    "        (\"system_num_protein_chains\", \"<=\", 5),\n",
    "        (\"system_num_ligand_chains\", \"<=\", 5),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of system neighboring protein chains\n",
    "plindex.groupby(\"system_num_protein_chains\").system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting specific data using _PLINDER_ annotations  <a class=\"anchor\" id=\"extracting-annotations\"></a>\n",
    "As we can see just from the data tables above - a significant fraction of _PLINDER_ systems contain complex multi protein chain systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task specific selection\n",
    "If we would like to focus on single protein and single ligand systems for training, we can use the annotated columns to filter out systems that:\n",
    "- contain only one protein chain\n",
    "- only one ligand\n",
    "\n",
    "Remember: In _PLINDER_ artifacts and (single atom) ions are also included in the index if they are part of the pocket.\n",
    "- `ligand_is_proper` combines columns `ligand_is_ion` and `ligand_is_artifact` to only select \"proper\" ligands.\n",
    "\n",
    "Let's find out how many annotated ligands are \"proper\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex.groupby(\"ligand_is_proper\").system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User choice\n",
    "\n",
    "The annotations table gives flexibility to choose the systems for training:\n",
    "- One could strictly choose to use only the data that contains single protein single ligand systems\n",
    "- Alternatively one could expand the number of systems to include systems containing single proper ligands, and optionally ignore the artifacts and ions in the pocket\n",
    "\n",
    "Let's compare the numbers of such systems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask for single receptor single ligand systems\n",
    "systems_1p1l = (plindex[\"system_num_protein_chains\"] == 1) & (plindex[\"system_num_ligand_chains\"] == 1)\n",
    "\n",
    "# create mask only for single receptor single \"proper\" ligand systems\n",
    "systems_proper_1p1l = (plindex[\"system_num_protein_chains\"] == 1) & (plindex[\"system_proper_num_ligand_chains\"] == 1) & plindex[\"ligand_is_proper\"]\n",
    "\n",
    "print(f\"Number of single receptor single ligand systems: {sum(systems_1p1l)}\")\n",
    "print(f\"Number of single receptor single \\\"proper\\\" ligand systems: {sum(systems_proper_1p1l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see - the second choice can provide up to 20% more data for training, however, the caveat is that some of the interactions made by artifacts or ions may influence the binding pose of the \"proper\" ligand. The user could come up with further strategies to filtering using annotations table or external tools, but this is beyond the scope of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading splits\n",
    "\n",
    "Now, after curating the systems of interest, let's have a look at the splits using _PLINDER_ API.\n",
    "\n",
    "- How to use {mod}`plinder.core` API to supply dataset inputs for `train` or `val` splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core import get_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the splits\n",
    "\n",
    "The `get_split` function provided the current _PLINDER_ split, the detailed description of this DataFrame is provide in the [dataset documentation](https://plinder-org.github.io/plinder/dataset.html#splits-splits), but for our practical purposes we are mostly interested in `system_id` and `split` that assigns each of our systems to a specific split category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current plinder split\n",
    "split_df = get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some specific method developers working on _flexible_ docking may also find handy the annotation column `system_has_apo_or_pred` indicating if the system has available `apo` or `pred` linked structures (see later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.groupby([\"split\", \"system_has_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity let's merge plindex and split DataFrames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to a single DataFrame\n",
    "plindex_split = plindex.merge(split_df, on=\"system_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting links to `apo` or `pred` structures <a class=\"anchor\" id=\"getting-apo-pred\"></a>\n",
    "\n",
    ":::{currentmodule} plinder.core\n",
    ":::\n",
    "\n",
    "For users interested in including `apo` and `pred` structures in their workflow, all the information needed can be obtained from the function {func}`query_links`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.scores import query_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = query_links(\n",
    "    columns=[\"reference_system_id\", \"id\", \"sort_score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} The table is sorted by `sort_score` that is resolution for `apo`s and `plddt` for `pred`s. The `apo` or `pred` is specified in the additionally added `filename` and `kind` column that specifies if the structure was sourced from PDB or AF2DB, respectively.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a user wants to consider only one linked structure per system - we can easily drop duplicates, first sorting by `sort_score`. Using this priority score, `pred` structures will not be used unless there is no `apo` available. Alternative can be achieved by sorting with `ascending=False`, or filtering by `kind==\"pred\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_links_df = links_df.sort_values(\"sort_score\", ascending=True).drop_duplicates(\"reference_system_id\")\n",
    "single_links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have links to `apo` / `pred` structures, we can see how many of those are available for our single protein single ligand systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_split[systems_1p1l].groupby([\"split\", \"system_has_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_split_1p1l_links = plindex_split[systems_1p1l].merge(single_links_df, left_on=\"system_id\", right_on=\"reference_system_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how many systems have linked structures\n",
    "plindex_split_1p1l_links['system_has_linked_apo_or_pred'] = ~plindex_split_1p1l_links.kind.isna()\n",
    "plindex_split_1p1l_links.groupby([\"split\", \"system_has_linked_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting final dataset\n",
    "Let's select only the set that has linked structures for flexible docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plindex_final_df = plindex_split_1p1l_links[\n",
    "    (plindex_split_1p1l_links.system_has_linked_apo_or_pred) & (plindex_split_1p1l_links.split != \"removed\")\n",
    "]\n",
    "plindex_final_df.groupby([\"split\", \"system_has_linked_apo_or_pred\"]).system_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using _PLINDER_ API to load dataset by split <a class=\"anchor\" id=\"api-load-split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.loader import get_model_input_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{currentmodule} plinder.core\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} function {func}`get_model_input_files` accepts `split =` \"train\", \"val\" or \"test\"\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = get_model_input_files(\n",
    "    plindex_final_df,\n",
    "    split = \"val\",\n",
    "    max_num_sample = 10,\n",
    "    num_alternative_structures = 1,\n",
    "    )\n",
    "print(f\"Loaded dataset size: {len(sample_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} if files not already available this downloads them to `~/.local/share/plinder/{PLINDER_RELEASE}/{PLINDER_ITERATION}` directory\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "sample_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using _PLINDER_ clusters in sampling <a class=\"anchor\" id=\"cluster-sampling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define diversity sampler function\n",
    ":::{currentmodule} plinder.core\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have provided an example of how one might use the function `get_diversity_samples` which is based on  `torch.utils.data.WeightedRandomSampler`.\n",
    "\n",
    "NOTE: This example function is provided for demonstration purposes and users are encouraged to come up with sampling strategy that suits their need. <br>\n",
    "\n",
    "In general, diversity can be sampled using cluster information described [here](https://plinder-org.github.io/plinder/dataset.html#clusters-clusters).\n",
    "All cluster information can easily be added to `plindex`. <br>\n",
    "\n",
    "See below an example, we are going to sample based on the following cluster label:\n",
    "`pli_qcov__70__community`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned DataFrame could then be passed to {func}`get_model_input_files` the same way `plindex_final_df` was used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plinder.core.loader.loader import get_diversity_samples\n",
    "\n",
    "cluster_column = \"pli_qcov__70__community\"\n",
    "plindex_clusters = query_index(columns=[\"system_id\", cluster_column])\n",
    "plindex_with_clusters = plindex_final_df.merge(plindex_clusters, on=\"system_id\", how=\"left\")\n",
    "sampled_df = get_diversity_samples(split_df=plindex_with_clusters, cluster_column=cluster_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
